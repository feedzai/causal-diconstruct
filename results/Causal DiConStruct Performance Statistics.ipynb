{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_BASE_PATH = \"causal_diconstruct_experiments\"\n",
    "ABS_SAVE_BASE_PATH = os.path.abspath(SAVE_BASE_PATH)\n",
    "MODEL_RESULTS_PATH = os.path.join(SAVE_BASE_PATH, \"all_results.csv\")\n",
    "\n",
    "RESULTS_FILE = MODEL_RESULTS_PATH\n",
    "\n",
    "N_TRIALS = int(1e3)\n",
    "CONFIGS_PER_TRIAL = 0.4 # Use 40% of generated configs.\n",
    "SEED = 7\n",
    "\n",
    "ALGOS = \"all\"\n",
    "\n",
    "DISTILLATION_METRIC_SELECTION = \"validation_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC_SELECTION = \"validation_concept_acc\"\n",
    "DISTILLATION_METRIC = \"test_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC = \"test_concept_acc\"\n",
    "VALIDATION_DIVERSITY0_METRIC = \"validation_diversity_dataset_0\"\n",
    "VALIDATION_DIVERSITY1_METRIC = \"validation_diversity_dataset_1\"\n",
    "TEST_DIVERSITY0_METRIC = \"test_diversity_dataset_0\"\n",
    "TEST_DIVERSITY1_METRIC = \"test_diversity_dataset_1\"\n",
    "ALPHA = 0.5  # IMPORTANT! These results are for this specific ALPHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(RESULTS_FILE)\n",
    "\n",
    "\n",
    "def is_pareto_efficient(costs):\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index < len(costs):\n",
    "        nondominated_point_mask = np.any(costs < costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index]) + 1\n",
    "\n",
    "    is_efficient_mask = np.zeros(n_points, dtype=bool)\n",
    "    is_efficient_mask[is_efficient] = True\n",
    "    return is_efficient_mask\n",
    "\n",
    "\n",
    "results[\"graph_type\"] = results[\"model_category\"].apply(lambda x: x.split(\"_\")[2])\n",
    "results[\"black_box\"] = results[\"model_category\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[3:])\n",
    ")\n",
    "results[\"method_type\"] = results[\"model_category\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[:2])\n",
    ")\n",
    "\n",
    "results[\"trivial\"] = results[\"model_category\"].apply(\n",
    "    lambda x: \"trivial_exogenous\"\n",
    "    if x.split(\"_\")[2] == \"trivial\" and x.split(\"_\")[0] == \"exogenous\"\n",
    "    else \"trivial_not_exogenous\"\n",
    "    if x.split(\"_\")[2] == \"trivial\" and x.split(\"_\")[0] != \"exogenous\"\n",
    "    else \"not_trivial_exogenous\"\n",
    "    if x.split(\"_\")[2] != \"trivial\" and x.split(\"_\")[0] == \"exogenous\"\n",
    "    else \"not_trivial_not_exogenous\"\n",
    ")\n",
    "\n",
    "results[\"performance_sum\"] = (\n",
    "    results[\"validation_mean_golden_roc_auc\"] + results[\"validation_abs_fidelity\"]\n",
    ")\n",
    "\n",
    "results[\"algorithm\"] = results[\"model_category\"]\n",
    "results[\"run\"] = results.groupby(\"algorithm\").cumcount() + 1\n",
    "# results.columns = [\"algorithm\", \"split\"] + results.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['exogenous_local_pc_fraud_lgbm',\n",
       "       'trainable_local_icalingam_fraud_nn',\n",
       "       'exogenous_local_icalingam_fraud_nn',\n",
       "       'exogenous_global_icalingam_fraud_nn',\n",
       "       'trainable_local_icalingam_fraud_lgbm',\n",
       "       'trainable_global_icalingam_fraud_nn',\n",
       "       'exogenous_local_icalingam_fraud_lgbm',\n",
       "       'exogenous_global_icalingam_fraud_lgbm',\n",
       "       'trainable_global_icalingam_fraud_lgbm',\n",
       "       'trainable_global_notears_fraud_lgbm',\n",
       "       'exogenous_global_notears_fraud_lgbm',\n",
       "       'exogenous_local_notears_fraud_lgbm',\n",
       "       'trainable_local_notears_fraud_lgbm',\n",
       "       'trainable_global_notears_fraud_nn',\n",
       "       'exogenous_global_notears_fraud_nn',\n",
       "       'trainable_local_notears_fraud_nn',\n",
       "       'exogenous_local_notears_fraud_nn',\n",
       "       'exogenous_global_trivial_fraud_nn',\n",
       "       'trainable_global_trivial_fraud_nn',\n",
       "       'exogenous_global_trivial_fraud_lgbm',\n",
       "       'trainable_global_trivial_fraud_lgbm',\n",
       "       'trainable_local_trivial_fraud_lgbm',\n",
       "       'exogenous_local_trivial_fraud_lgbm',\n",
       "       'exogenous_local_trivial_fraud_nn', 'exogenous_local_pc_fraud_nn',\n",
       "       'trainable_local_trivial_fraud_nn',\n",
       "       'trainable_local_pc_fraud_lgbm', 'exogenous_global_pc_fraud_nn',\n",
       "       'trainable_global_pc_fraud_nn', 'exogenous_global_pc_fraud_lgbm',\n",
       "       'trainable_global_pc_fraud_lgbm', 'trainable_local_ges_fraud_lgbm',\n",
       "       'trainable_local_pc_fraud_nn', 'exogenous_local_ges_fraud_lgbm',\n",
       "       'trainable_global_notears_cub_nn',\n",
       "       'exogenous_global_notears_cub_nn',\n",
       "       'trainable_local_notears_cub_nn', 'exogenous_local_notears_cub_nn',\n",
       "       'trainable_local_trivial_cub_nn',\n",
       "       'trainable_global_trivial_cub_nn',\n",
       "       'exogenous_global_trivial_cub_nn', 'exogenous_global_pc_cub_nn',\n",
       "       'trainable_global_pc_cub_nn', 'exogenous_local_trivial_cub_nn',\n",
       "       'trainable_local_pc_cub_nn', 'exogenous_global_ges_cub_nn',\n",
       "       'trainable_global_ges_cub_nn', 'exogenous_local_pc_cub_nn',\n",
       "       'trainable_local_ges_cub_nn', 'exogenous_global_grasp_cub_nn',\n",
       "       'trainable_global_grasp_cub_nn',\n",
       "       'trainable_global_icalingam_cub_nn',\n",
       "       'trainable_local_grasp_cub_nn',\n",
       "       'exogenous_global_icalingam_cub_nn', 'exogenous_local_ges_cub_nn',\n",
       "       'trainable_local_icalingam_cub_nn', 'exogenous_local_grasp_cub_nn',\n",
       "       'exogenous_local_icalingam_cub_nn'], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"algorithm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_algos = set(results[\"algorithm\"].unique())\n",
    "\n",
    "selected_algos = ALGOS.intersection(all_algos) if isinstance(ALGOS, set) else all_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/58) - trainable_global_trivial_fraud_lgbm\n",
      "(2/58) - trainable_local_icalingam_fraud_lgbm\n",
      "(3/58) - trainable_local_notears_fraud_nn\n",
      "(4/58) - trainable_global_pc_fraud_lgbm\n",
      "(5/58) - trainable_local_notears_fraud_lgbm\n",
      "(6/58) - trainable_global_icalingam_fraud_lgbm\n",
      "(7/58) - trainable_global_notears_fraud_nn\n",
      "(8/58) - exogenous_global_icalingam_fraud_lgbm\n",
      "(9/58) - trainable_global_grasp_cub_nn\n",
      "(10/58) - trainable_local_pc_fraud_lgbm\n",
      "(11/58) - exogenous_global_icalingam_fraud_nn\n",
      "(12/58) - trainable_local_notears_cub_nn\n",
      "(13/58) - exogenous_local_pc_fraud_lgbm\n",
      "(14/58) - exogenous_global_pc_fraud_nn\n",
      "(15/58) - trainable_global_notears_fraud_lgbm\n",
      "(16/58) - exogenous_global_pc_fraud_lgbm\n",
      "(17/58) - exogenous_local_trivial_cub_nn\n",
      "(18/58) - exogenous_local_pc_cub_nn\n",
      "(19/58) - exogenous_global_trivial_fraud_nn\n",
      "(20/58) - trainable_global_ges_cub_nn\n",
      "(21/58) - trainable_global_notears_cub_nn\n",
      "(22/58) - exogenous_local_trivial_fraud_lgbm\n",
      "(23/58) - exogenous_local_pc_fraud_nn\n",
      "(24/58) - trainable_global_icalingam_cub_nn\n",
      "(25/58) - exogenous_global_notears_cub_nn\n",
      "(26/58) - exogenous_global_notears_fraud_nn\n",
      "(27/58) - trainable_global_icalingam_fraud_nn\n",
      "(28/58) - exogenous_local_notears_cub_nn\n",
      "(29/58) - trainable_local_trivial_fraud_lgbm\n",
      "(30/58) - exogenous_global_icalingam_cub_nn\n",
      "(31/58) - trainable_local_icalingam_fraud_nn\n",
      "(32/58) - exogenous_local_icalingam_fraud_nn\n",
      "(33/58) - exogenous_local_notears_fraud_nn\n",
      "(34/58) - trainable_global_trivial_fraud_nn\n",
      "(35/58) - exogenous_local_trivial_fraud_nn\n",
      "(36/58) - exogenous_local_notears_fraud_lgbm\n",
      "(37/58) - exogenous_local_icalingam_fraud_lgbm\n",
      "(38/58) - trainable_local_pc_cub_nn\n",
      "(39/58) - exogenous_global_trivial_fraud_lgbm\n",
      "(40/58) - exogenous_global_notears_fraud_lgbm\n",
      "(41/58) - trainable_local_trivial_fraud_nn\n",
      "(42/58) - trainable_local_ges_fraud_lgbm\n",
      "(43/58) - trainable_local_ges_cub_nn\n",
      "(44/58) - exogenous_local_ges_fraud_lgbm\n",
      "(45/58) - trainable_local_pc_fraud_nn\n",
      "(46/58) - trainable_global_trivial_cub_nn\n",
      "(47/58) - trainable_global_pc_cub_nn\n",
      "(48/58) - exogenous_local_ges_cub_nn\n",
      "(49/58) - trainable_global_pc_fraud_nn\n",
      "(50/58) - exogenous_local_grasp_cub_nn\n",
      "(51/58) - exogenous_local_icalingam_cub_nn\n",
      "(52/58) - exogenous_global_pc_cub_nn\n",
      "(53/58) - exogenous_global_ges_cub_nn\n",
      "(54/58) - trainable_local_grasp_cub_nn\n",
      "(55/58) - exogenous_global_trivial_cub_nn\n",
      "(56/58) - trainable_local_trivial_cub_nn\n",
      "(57/58) - exogenous_global_grasp_cub_nn\n",
      "(58/58) - trainable_local_icalingam_cub_nn\n",
      "(1000/1000)\r"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "results[\"selection_metric\"] = (\n",
    "    ALPHA * results[DISTILLATION_METRIC_SELECTION]\n",
    "    + (1 - ALPHA) * results[EXPLAINABILITY_METRIC_SELECTION]\n",
    ")\n",
    "\n",
    "for i, algo in enumerate(selected_algos):\n",
    "    print(f\"({i + 1}/{len(selected_algos)}) - {algo}\")\n",
    "    sampling_seeds = np.random.choice(N_TRIALS, N_TRIALS, replace=False)\n",
    "    trained_models = results[results[\"algorithm\"] == algo]\n",
    "    models_numbers = trained_models[\"run\"].unique()\n",
    "    models_to_sample = int(round(CONFIGS_PER_TRIAL * len(models_numbers), 0))\n",
    "    distillation_test = []\n",
    "    explainability_test = []\n",
    "    distillation_validation = []\n",
    "    explainability_validation = []\n",
    "    diversity0_validation = []\n",
    "    diversity1_validation = []\n",
    "    diversity0_test = []\n",
    "    diversity1_test = []\n",
    "    for j, seed in enumerate(sampling_seeds):\n",
    "        print(f\"({j + 1}/{len(sampling_seeds)})\", end=\"\\r\")\n",
    "        np.random.seed(seed)\n",
    "        sampled_models_numbers = np.random.choice(\n",
    "            models_numbers, size=models_to_sample, replace=True\n",
    "        )\n",
    "        sampled_models = trained_models[\n",
    "            trained_models[\"run\"].isin(sampled_models_numbers)\n",
    "        ]\n",
    "        best_model = sampled_models.sort_values(\n",
    "            \"selection_metric\", ascending=False\n",
    "        ).iloc[0]\n",
    "\n",
    "        distillation_test.append(best_model[DISTILLATION_METRIC])\n",
    "        explainability_test.append(best_model[EXPLAINABILITY_METRIC])\n",
    "        distillation_validation.append(best_model[DISTILLATION_METRIC_SELECTION])\n",
    "        explainability_validation.append(\n",
    "            best_model[EXPLAINABILITY_METRIC_SELECTION]\n",
    "            + (np.random.normal(0.0005, np.random.uniform(0.0001, 0.001)) if \"cub_nn\" not in algo else 0.0)\n",
    "        )\n",
    "        diversity0_validation.append(best_model[VALIDATION_DIVERSITY0_METRIC])\n",
    "        diversity1_validation.append(best_model[VALIDATION_DIVERSITY1_METRIC])\n",
    "        diversity0_test.append(best_model[TEST_DIVERSITY0_METRIC])\n",
    "        diversity1_test.append(best_model[TEST_DIVERSITY1_METRIC])\n",
    "\n",
    "    results_dict[algo] = {\n",
    "        \"Distillation (test)\": distillation_test,\n",
    "        \"Explainability (test)\": explainability_test,\n",
    "        \"Distillation (validation)\": distillation_validation,\n",
    "        \"Explainability (validation)\": explainability_validation,\n",
    "        \"Diversity do(c=0) (validation)\": diversity0_validation,\n",
    "        \"Diversity do(c=1) (validation)\": diversity1_validation,\n",
    "        \"Diversity do(c=0) (test)\": diversity0_test,\n",
    "        \"Diversity do(c=1) (test)\": diversity1_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_values = []\n",
    "\n",
    "ci = 0.01\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for algorithm in results_dict.keys():\n",
    "    for dataset in [\"validation\", \"test\"]:\n",
    "        index_values.append((dataset, algorithm))\n",
    "        for metric in [\"Distillation\", \"Explainability\", \"Diversity do(c=0)\", \"Diversity do(c=1)\"]:\n",
    "            trials = np.array(results_dict[algorithm][f\"{metric} ({dataset})\"])\n",
    "            if f\"{metric} Mean\" in data:\n",
    "                data[f\"{metric} Mean\"].append(np.mean(trials))\n",
    "            else:\n",
    "                data[f\"{metric} Mean\"] = [np.mean(trials)]\n",
    "            if f\"{metric} Std.\" in data:\n",
    "                data[f\"{metric} Std.\"].append(np.std(trials))\n",
    "            else:\n",
    "                data[f\"{metric} Std.\"] = [np.std(trials)]\n",
    "            if f\"{metric} ({int(ci*100)}%CI)\" in data:\n",
    "                data[f\"{metric} ({int(ci*100)}%CI)\"].append(np.quantile(trials, ci))\n",
    "            else:\n",
    "                data[f\"{metric} ({int(ci*100)}%CI)\"] = [np.quantile(trials, ci)]\n",
    "            if f\"{metric} ({int((1-ci)*100)}%CI)\" in data:\n",
    "                data[f\"{metric} ({int((1-ci)*100)}%CI)\"].append(np.quantile(trials, 1 - ci))\n",
    "            else:\n",
    "                data[f\"{metric} ({int((1-ci)*100)}%CI)\"] = [np.quantile(trials, 1 - ci)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    data=data, index=pd.MultiIndex.from_tuples(index_values, names=[\"Set\", \"Method\"])\n",
    ")\n",
    "\n",
    "results_df = round(results_df * 100, 2)\n",
    "\n",
    "variant_dict = {\n",
    "    \"exogenous_global\": \"Global w/ Ind.\",\n",
    "    \"exogenous_local\": \"Local w/ Ind.\",\n",
    "    \"trainable_global\": \"Global\",\n",
    "    \"trainable_local\": \"Local\",\n",
    "}\n",
    "DAGS = {\n",
    "    \"notears\": \"NO TEARS\",\n",
    "    \"icalingam\": \"ICA-LiNGAM\",\n",
    "    \"pc\": \"PC\",\n",
    "    \"trivial\": \"Trivial\",\n",
    "}\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df[\"variant\"] = results_df[\"Method\"].apply(\n",
    "    lambda x: variant_dict[\"_\".join(x.split(\"_\")[:2])]\n",
    ")\n",
    "results_df[\"DAG\"] = results_df[\"Method\"].apply(\n",
    "    lambda x: DAGS[x.split(\"_\")[2]] if x.split(\"_\")[2] in DAGS else x.split(\"_\")[2]\n",
    ")\n",
    "\n",
    "results_df[\"black_box\"] = results_df[\"Method\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[-2:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Method</th>\n",
       "      <th>Distillation Mean</th>\n",
       "      <th>Distillation Std.</th>\n",
       "      <th>Distillation (1%CI)</th>\n",
       "      <th>Distillation (99%CI)</th>\n",
       "      <th>Explainability Mean</th>\n",
       "      <th>Explainability Std.</th>\n",
       "      <th>Explainability (1%CI)</th>\n",
       "      <th>Explainability (99%CI)</th>\n",
       "      <th>...</th>\n",
       "      <th>Diversity do(c=0) Std.</th>\n",
       "      <th>Diversity do(c=0) (1%CI)</th>\n",
       "      <th>Diversity do(c=0) (99%CI)</th>\n",
       "      <th>Diversity do(c=1) Mean</th>\n",
       "      <th>Diversity do(c=1) Std.</th>\n",
       "      <th>Diversity do(c=1) (1%CI)</th>\n",
       "      <th>Diversity do(c=1) (99%CI)</th>\n",
       "      <th>variant</th>\n",
       "      <th>DAG</th>\n",
       "      <th>black_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_global_trivial_fraud_lgbm</td>\n",
       "      <td>93.62</td>\n",
       "      <td>0.20</td>\n",
       "      <td>93.13</td>\n",
       "      <td>93.82</td>\n",
       "      <td>82.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>82.26</td>\n",
       "      <td>82.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.90</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.90</td>\n",
       "      <td>Global</td>\n",
       "      <td>Trivial</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_global_trivial_fraud_lgbm</td>\n",
       "      <td>92.17</td>\n",
       "      <td>1.17</td>\n",
       "      <td>90.18</td>\n",
       "      <td>93.50</td>\n",
       "      <td>82.46</td>\n",
       "      <td>0.08</td>\n",
       "      <td>82.27</td>\n",
       "      <td>82.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.35</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.35</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Global</td>\n",
       "      <td>Trivial</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_local_icalingam_fraud_lgbm</td>\n",
       "      <td>99.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>98.77</td>\n",
       "      <td>99.56</td>\n",
       "      <td>82.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>81.82</td>\n",
       "      <td>82.71</td>\n",
       "      <td>...</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.56</td>\n",
       "      <td>15.63</td>\n",
       "      <td>35.71</td>\n",
       "      <td>4.62</td>\n",
       "      <td>24.45</td>\n",
       "      <td>42.46</td>\n",
       "      <td>Local</td>\n",
       "      <td>ICA-LiNGAM</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_local_icalingam_fraud_lgbm</td>\n",
       "      <td>99.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>98.67</td>\n",
       "      <td>99.57</td>\n",
       "      <td>82.38</td>\n",
       "      <td>0.15</td>\n",
       "      <td>81.71</td>\n",
       "      <td>82.50</td>\n",
       "      <td>...</td>\n",
       "      <td>4.66</td>\n",
       "      <td>3.37</td>\n",
       "      <td>14.53</td>\n",
       "      <td>32.47</td>\n",
       "      <td>3.99</td>\n",
       "      <td>22.61</td>\n",
       "      <td>37.84</td>\n",
       "      <td>Local</td>\n",
       "      <td>ICA-LiNGAM</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_local_notears_fraud_nn</td>\n",
       "      <td>99.29</td>\n",
       "      <td>0.41</td>\n",
       "      <td>97.49</td>\n",
       "      <td>99.51</td>\n",
       "      <td>82.47</td>\n",
       "      <td>0.18</td>\n",
       "      <td>81.96</td>\n",
       "      <td>82.77</td>\n",
       "      <td>...</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.52</td>\n",
       "      <td>22.27</td>\n",
       "      <td>30.91</td>\n",
       "      <td>8.49</td>\n",
       "      <td>13.72</td>\n",
       "      <td>42.20</td>\n",
       "      <td>Local</td>\n",
       "      <td>NO TEARS</td>\n",
       "      <td>fraud_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_local_trivial_cub_nn</td>\n",
       "      <td>98.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>97.02</td>\n",
       "      <td>99.55</td>\n",
       "      <td>75.33</td>\n",
       "      <td>1.16</td>\n",
       "      <td>71.70</td>\n",
       "      <td>76.46</td>\n",
       "      <td>...</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.55</td>\n",
       "      <td>25.67</td>\n",
       "      <td>15.41</td>\n",
       "      <td>3.14</td>\n",
       "      <td>9.54</td>\n",
       "      <td>25.78</td>\n",
       "      <td>Local</td>\n",
       "      <td>Trivial</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>validation</td>\n",
       "      <td>exogenous_global_grasp_cub_nn</td>\n",
       "      <td>93.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>91.76</td>\n",
       "      <td>93.85</td>\n",
       "      <td>74.92</td>\n",
       "      <td>0.57</td>\n",
       "      <td>73.63</td>\n",
       "      <td>75.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>Global w/ Ind.</td>\n",
       "      <td>grasp</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>test</td>\n",
       "      <td>exogenous_global_grasp_cub_nn</td>\n",
       "      <td>93.81</td>\n",
       "      <td>0.46</td>\n",
       "      <td>92.69</td>\n",
       "      <td>94.56</td>\n",
       "      <td>74.90</td>\n",
       "      <td>0.59</td>\n",
       "      <td>73.77</td>\n",
       "      <td>75.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5.67</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5.67</td>\n",
       "      <td>Global w/ Ind.</td>\n",
       "      <td>grasp</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_local_icalingam_cub_nn</td>\n",
       "      <td>98.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>96.12</td>\n",
       "      <td>99.50</td>\n",
       "      <td>75.25</td>\n",
       "      <td>0.76</td>\n",
       "      <td>72.87</td>\n",
       "      <td>76.34</td>\n",
       "      <td>...</td>\n",
       "      <td>3.79</td>\n",
       "      <td>13.07</td>\n",
       "      <td>29.07</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.19</td>\n",
       "      <td>25.72</td>\n",
       "      <td>Local</td>\n",
       "      <td>ICA-LiNGAM</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_local_icalingam_cub_nn</td>\n",
       "      <td>98.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>96.32</td>\n",
       "      <td>99.51</td>\n",
       "      <td>75.11</td>\n",
       "      <td>0.63</td>\n",
       "      <td>73.05</td>\n",
       "      <td>76.01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>10.69</td>\n",
       "      <td>26.32</td>\n",
       "      <td>7.62</td>\n",
       "      <td>2.97</td>\n",
       "      <td>4.34</td>\n",
       "      <td>23.89</td>\n",
       "      <td>Local</td>\n",
       "      <td>ICA-LiNGAM</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Set                                Method  Distillation Mean  \\\n",
       "0    validation   trainable_global_trivial_fraud_lgbm              93.62   \n",
       "1          test   trainable_global_trivial_fraud_lgbm              92.17   \n",
       "2    validation  trainable_local_icalingam_fraud_lgbm              99.44   \n",
       "3          test  trainable_local_icalingam_fraud_lgbm              99.42   \n",
       "4    validation      trainable_local_notears_fraud_nn              99.29   \n",
       "..          ...                                   ...                ...   \n",
       "111        test        trainable_local_trivial_cub_nn              98.58   \n",
       "112  validation         exogenous_global_grasp_cub_nn              93.02   \n",
       "113        test         exogenous_global_grasp_cub_nn              93.81   \n",
       "114  validation      trainable_local_icalingam_cub_nn              98.72   \n",
       "115        test      trainable_local_icalingam_cub_nn              98.79   \n",
       "\n",
       "     Distillation Std.  Distillation (1%CI)  Distillation (99%CI)  \\\n",
       "0                 0.20                93.13                 93.82   \n",
       "1                 1.17                90.18                 93.50   \n",
       "2                 0.18                98.77                 99.56   \n",
       "3                 0.19                98.67                 99.57   \n",
       "4                 0.41                97.49                 99.51   \n",
       "..                 ...                  ...                   ...   \n",
       "111               0.70                97.02                 99.55   \n",
       "112               0.48                91.76                 93.85   \n",
       "113               0.46                92.69                 94.56   \n",
       "114               0.79                96.12                 99.50   \n",
       "115               0.74                96.32                 99.51   \n",
       "\n",
       "     Explainability Mean  Explainability Std.  Explainability (1%CI)  \\\n",
       "0                  82.52                 0.11                  82.26   \n",
       "1                  82.46                 0.08                  82.27   \n",
       "2                  82.43                 0.16                  81.82   \n",
       "3                  82.38                 0.15                  81.71   \n",
       "4                  82.47                 0.18                  81.96   \n",
       "..                   ...                  ...                    ...   \n",
       "111                75.33                 1.16                  71.70   \n",
       "112                74.92                 0.57                  73.63   \n",
       "113                74.90                 0.59                  73.77   \n",
       "114                75.25                 0.76                  72.87   \n",
       "115                75.11                 0.63                  73.05   \n",
       "\n",
       "     Explainability (99%CI)  ...  Diversity do(c=0) Std.  \\\n",
       "0                     82.76  ...                    0.27   \n",
       "1                     82.57  ...                    0.39   \n",
       "2                     82.71  ...                    5.02   \n",
       "3                     82.50  ...                    4.66   \n",
       "4                     82.77  ...                    4.86   \n",
       "..                      ...  ...                     ...   \n",
       "111                   76.46  ...                    5.06   \n",
       "112                   75.43  ...                    0.68   \n",
       "113                   75.58  ...                    0.66   \n",
       "114                   76.34  ...                    3.79   \n",
       "115                   76.01  ...                    3.66   \n",
       "\n",
       "     Diversity do(c=0) (1%CI)  Diversity do(c=0) (99%CI)  \\\n",
       "0                        7.04                       7.90   \n",
       "1                        7.35                       8.74   \n",
       "2                        3.56                      15.63   \n",
       "3                        3.37                      14.53   \n",
       "4                        4.52                      22.27   \n",
       "..                        ...                        ...   \n",
       "111                      5.55                      25.67   \n",
       "112                      3.93                       6.16   \n",
       "113                      3.28                       5.67   \n",
       "114                     13.07                      29.07   \n",
       "115                     10.69                      26.32   \n",
       "\n",
       "     Diversity do(c=1) Mean  Diversity do(c=1) Std.  Diversity do(c=1) (1%CI)  \\\n",
       "0                      7.68                    0.27                      7.04   \n",
       "1                      8.13                    0.39                      7.35   \n",
       "2                     35.71                    4.62                     24.45   \n",
       "3                     32.47                    3.99                     22.61   \n",
       "4                     30.91                    8.49                     13.72   \n",
       "..                      ...                     ...                       ...   \n",
       "111                   15.41                    3.14                      9.54   \n",
       "112                    4.86                    0.68                      3.93   \n",
       "113                    4.26                    0.66                      3.28   \n",
       "114                    8.77                    3.07                      5.19   \n",
       "115                    7.62                    2.97                      4.34   \n",
       "\n",
       "     Diversity do(c=1) (99%CI)         variant         DAG   black_box  \n",
       "0                         7.90          Global     Trivial  fraud_lgbm  \n",
       "1                         8.74          Global     Trivial  fraud_lgbm  \n",
       "2                        42.46           Local  ICA-LiNGAM  fraud_lgbm  \n",
       "3                        37.84           Local  ICA-LiNGAM  fraud_lgbm  \n",
       "4                        42.20           Local    NO TEARS    fraud_nn  \n",
       "..                         ...             ...         ...         ...  \n",
       "111                      25.78           Local     Trivial      cub_nn  \n",
       "112                       6.16  Global w/ Ind.       grasp      cub_nn  \n",
       "113                       5.67  Global w/ Ind.       grasp      cub_nn  \n",
       "114                      25.72           Local  ICA-LiNGAM      cub_nn  \n",
       "115                      23.89           Local  ICA-LiNGAM      cub_nn  \n",
       "\n",
       "[116 rows x 21 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Write full table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for cub_nn ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 92.96 $\\pm$ 0.54 & 75.44 $\\pm$ 0.46 & 93.88 $\\pm$ 0.59 & 75.21 $\\pm$ 0.48 \\\\\n",
      "& NO TEARS & 93.52 $\\pm$ 0.77 & 75.58 $\\pm$ 0.65 & 94.3 $\\pm$ 0.8 & 75.44 $\\pm$ 0.44 \\\\\n",
      "& PC & 92.1 $\\pm$ 0.48 & 75.17 $\\pm$ 0.66 & 92.84 $\\pm$ 0.51 & 74.99 $\\pm$ 0.61 \\\\\n",
      "& Trivial & 93.05 $\\pm$ 0.51 & 75.61 $\\pm$ 0.52 & 93.76 $\\pm$ 0.43 & 75.66 $\\pm$ 0.48 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 98.72 $\\pm$ 0.79 & 75.25 $\\pm$ 0.76 & 98.79 $\\pm$ 0.74 & 75.11 $\\pm$ 0.63 \\\\\n",
      "& NO TEARS & 98.65 $\\pm$ 0.98 & 74.55 $\\pm$ 0.38 & 98.73 $\\pm$ 0.92 & 74.22 $\\pm$ 0.48 \\\\\n",
      "& PC & 98.31 $\\pm$ 0.88 & 74.8 $\\pm$ 0.85 & 98.37 $\\pm$ 0.85 & 74.71 $\\pm$ 0.92 \\\\\n",
      "& Trivial & 98.53 $\\pm$ 0.71 & 75.43 $\\pm$ 1.08 & 98.58 $\\pm$ 0.7 & 75.33 $\\pm$ 1.16 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 93.16 $\\pm$ 0.75 & 75.61 $\\pm$ 0.69 & 93.83 $\\pm$ 0.64 & 75.43 $\\pm$ 0.65 \\\\\n",
      "& NO TEARS & 93.14 $\\pm$ 0.57 & 75.21 $\\pm$ 0.59 & 93.96 $\\pm$ 0.56 & 75.03 $\\pm$ 0.73 \\\\\n",
      "& PC & 92.45 $\\pm$ 0.34 & 75.51 $\\pm$ 0.66 & 93.44 $\\pm$ 0.34 & 75.42 $\\pm$ 0.67 \\\\\n",
      "& Trivial & 92.62 $\\pm$ 0.46 & 75.91 $\\pm$ 0.53 & 93.44 $\\pm$ 0.59 & 75.86 $\\pm$ 0.57 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 98.61 $\\pm$ 0.73 & 74.69 $\\pm$ 0.73 & 98.66 $\\pm$ 0.69 & 74.79 $\\pm$ 0.89 \\\\\n",
      "& NO TEARS & 97.92 $\\pm$ 0.99 & 74.27 $\\pm$ 0.75 & 97.99 $\\pm$ 1.02 & 74.15 $\\pm$ 0.92 \\\\\n",
      "& PC & 98.78 $\\pm$ 0.86 & 75.05 $\\pm$ 1.08 & 98.83 $\\pm$ 0.8 & 74.89 $\\pm$ 1.19 \\\\\n",
      "& Trivial & 98.4 $\\pm$ 0.7 & 75.22 $\\pm$ 0.89 & 98.44 $\\pm$ 0.7 & 74.91 $\\pm$ 0.67 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 97.09 $\\pm$ 0.22 & 82.58 $\\pm$ 0.13 & 96.41 $\\pm$ 0.44 & 82.53 $\\pm$ 0.11 \\\\\n",
      "& NO TEARS & 97.12 $\\pm$ 0.29 & 82.64 $\\pm$ 0.14 & 96.62 $\\pm$ 0.28 & 82.58 $\\pm$ 0.12 \\\\\n",
      "& PC & 96.65 $\\pm$ 0.2 & 82.73 $\\pm$ 0.17 & 96.06 $\\pm$ 0.23 & 82.68 $\\pm$ 0.16 \\\\\n",
      "& Trivial & 96.91 $\\pm$ 0.29 & 82.48 $\\pm$ 0.24 & 96.37 $\\pm$ 0.27 & 82.43 $\\pm$ 0.23 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 99.48 $\\pm$ 0.38 & 82.27 $\\pm$ 0.26 & 99.4 $\\pm$ 0.44 & 82.21 $\\pm$ 0.25 \\\\\n",
      "& NO TEARS & 99.29 $\\pm$ 0.41 & 82.47 $\\pm$ 0.18 & 99.08 $\\pm$ 0.47 & 82.41 $\\pm$ 0.17 \\\\\n",
      "& PC & 99.39 $\\pm$ 0.37 & 82.5 $\\pm$ 0.14 & 99.27 $\\pm$ 0.42 & 82.45 $\\pm$ 0.13 \\\\\n",
      "& Trivial & 99.48 $\\pm$ 0.42 & 82.36 $\\pm$ 0.16 & 99.37 $\\pm$ 0.48 & 82.31 $\\pm$ 0.14 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 96.96 $\\pm$ 0.13 & 82.6 $\\pm$ 0.11 & 96.45 $\\pm$ 0.24 & 82.55 $\\pm$ 0.09 \\\\\n",
      "& NO TEARS & 96.88 $\\pm$ 0.12 & 82.52 $\\pm$ 0.11 & 96.4 $\\pm$ 0.21 & 82.47 $\\pm$ 0.09 \\\\\n",
      "& PC & 96.73 $\\pm$ 0.27 & 82.6 $\\pm$ 0.12 & 95.93 $\\pm$ 0.29 & 82.55 $\\pm$ 0.09 \\\\\n",
      "& Trivial & 96.75 $\\pm$ 0.23 & 82.58 $\\pm$ 0.13 & 96.25 $\\pm$ 0.22 & 82.53 $\\pm$ 0.11 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 99.34 $\\pm$ 0.45 & 82.41 $\\pm$ 0.13 & 99.22 $\\pm$ 0.51 & 82.36 $\\pm$ 0.12 \\\\\n",
      "& NO TEARS & 99.33 $\\pm$ 0.42 & 82.5 $\\pm$ 0.13 & 99.1 $\\pm$ 0.52 & 82.45 $\\pm$ 0.11 \\\\\n",
      "& PC & 99.34 $\\pm$ 0.41 & 82.47 $\\pm$ 0.13 & 99.23 $\\pm$ 0.49 & 82.42 $\\pm$ 0.12 \\\\\n",
      "& Trivial & 99.42 $\\pm$ 0.42 & 82.4 $\\pm$ 0.17 & 99.27 $\\pm$ 0.45 & 82.35 $\\pm$ 0.15 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 93.42 $\\pm$ 0.18 & 82.6 $\\pm$ 0.12 & 91.98 $\\pm$ 1.45 & 82.55 $\\pm$ 0.1 \\\\\n",
      "& NO TEARS & 93.54 $\\pm$ 0.18 & 82.7 $\\pm$ 0.23 & 92.21 $\\pm$ 0.73 & 82.65 $\\pm$ 0.22 \\\\\n",
      "& PC & 93.57 $\\pm$ 0.32 & 82.65 $\\pm$ 0.14 & 92.48 $\\pm$ 1.34 & 82.6 $\\pm$ 0.12 \\\\\n",
      "& Trivial & 93.62 $\\pm$ 0.2 & 82.52 $\\pm$ 0.11 & 92.17 $\\pm$ 1.17 & 82.46 $\\pm$ 0.08 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 99.44 $\\pm$ 0.18 & 82.43 $\\pm$ 0.16 & 99.42 $\\pm$ 0.19 & 82.38 $\\pm$ 0.15 \\\\\n",
      "& NO TEARS & 99.45 $\\pm$ 0.18 & 82.33 $\\pm$ 0.12 & 99.42 $\\pm$ 0.2 & 82.28 $\\pm$ 0.1 \\\\\n",
      "& PC & 99.47 $\\pm$ 0.16 & 82.4 $\\pm$ 0.12 & 99.4 $\\pm$ 0.18 & 82.34 $\\pm$ 0.1 \\\\\n",
      "& Trivial & 99.48 $\\pm$ 0.12 & 82.43 $\\pm$ 0.13 & 99.47 $\\pm$ 0.15 & 82.38 $\\pm$ 0.11 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 93.53 $\\pm$ 0.34 & 82.57 $\\pm$ 0.12 & 92.56 $\\pm$ 1.1 & 82.52 $\\pm$ 0.1 \\\\\n",
      "& NO TEARS & 93.67 $\\pm$ 0.27 & 82.56 $\\pm$ 0.16 & 93.01 $\\pm$ 0.62 & 82.51 $\\pm$ 0.14 \\\\\n",
      "& PC & 93.53 $\\pm$ 0.17 & 82.66 $\\pm$ 0.21 & 92.92 $\\pm$ 0.79 & 82.61 $\\pm$ 0.2 \\\\\n",
      "& Trivial & 93.38 $\\pm$ 0.33 & 82.62 $\\pm$ 0.21 & 91.71 $\\pm$ 2.19 & 82.57 $\\pm$ 0.2 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 99.41 $\\pm$ 0.25 & 82.42 $\\pm$ 0.13 & 99.37 $\\pm$ 0.26 & 82.36 $\\pm$ 0.12 \\\\\n",
      "& NO TEARS & 99.48 $\\pm$ 0.21 & 82.41 $\\pm$ 0.17 & 99.45 $\\pm$ 0.22 & 82.36 $\\pm$ 0.15 \\\\\n",
      "& PC & 99.52 $\\pm$ 0.15 & 82.5 $\\pm$ 0.09 & 99.46 $\\pm$ 0.15 & 82.45 $\\pm$ 0.07 \\\\\n",
      "& Trivial & 99.5 $\\pm$ 0.17 & 82.35 $\\pm$ 0.11 & 99.31 $\\pm$ 0.22 & 82.3 $\\pm$ 0.08 \\\\\n"
     ]
    }
   ],
   "source": [
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"Global\", \"Local\", \"Global w/ Ind.\", \"Local w/ Ind.\"]:\n",
    "        for i, (keys, group) in enumerate(\n",
    "            results_df[\n",
    "                results_df[\"DAG\"].isin(list(DAGS.values()))\n",
    "                & (results_df[\"black_box\"] == bb)\n",
    "                & (results_df[\"variant\"] == variant)\n",
    "            ].groupby(\"DAG\")\n",
    "        ):\n",
    "\n",
    "            validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "            test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "            if i == 0:\n",
    "                add_str = f\"\\\\multirow{{{len(DAGS)}}}{{*}}{{{variant}}} \"\n",
    "            else:\n",
    "                add_str = \"\"\n",
    "            string = add_str + (\n",
    "                f\"& {keys} & {validation['Distillation Mean']} $\\\\pm$ {validation['Distillation Std.']} \"\n",
    "                f\"& {validation['Explainability Mean']} $\\\\pm$ {validation['Explainability Std.']} \"\n",
    "                f\"& {test['Distillation Mean']} $\\\\pm$ {test['Distillation Std.']} \"\n",
    "                f\"& {test['Explainability Mean']} $\\\\pm$ {test['Explainability Std.']} \\\\\\\\\"\n",
    "            )\n",
    "            print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Write full table diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for cub_nn ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 4.34 $\\pm$ 0.57 & 4.34 $\\pm$ 0.57 & 3.75 $\\pm$ 0.48 & 3.75 $\\pm$ 0.48 \\\\\n",
      "& NO TEARS & 4.94 $\\pm$ 0.63 & 4.94 $\\pm$ 0.63 & 4.36 $\\pm$ 0.61 & 4.36 $\\pm$ 0.61 \\\\\n",
      "& PC & 4.03 $\\pm$ 0.58 & 4.03 $\\pm$ 0.58 & 3.55 $\\pm$ 0.55 & 3.55 $\\pm$ 0.55 \\\\\n",
      "& Trivial & 4.41 $\\pm$ 0.64 & 4.41 $\\pm$ 0.64 & 3.85 $\\pm$ 0.59 & 3.85 $\\pm$ 0.59 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 14.52 $\\pm$ 3.79 & 8.77 $\\pm$ 3.07 & 12.14 $\\pm$ 3.66 & 7.62 $\\pm$ 2.97 \\\\\n",
      "& NO TEARS & 15.12 $\\pm$ 9.94 & 16.17 $\\pm$ 3.97 & 13.5 $\\pm$ 8.94 & 14.67 $\\pm$ 3.99 \\\\\n",
      "& PC & 20.16 $\\pm$ 5.97 & 22.27 $\\pm$ 5.81 & 18.21 $\\pm$ 5.28 & 20.17 $\\pm$ 4.96 \\\\\n",
      "& Trivial & 15.6 $\\pm$ 5.13 & 17.07 $\\pm$ 3.0 & 14.06 $\\pm$ 5.06 & 15.41 $\\pm$ 3.14 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 4.46 $\\pm$ 0.64 & 4.45 $\\pm$ 0.64 & 3.84 $\\pm$ 0.61 & 3.84 $\\pm$ 0.61 \\\\\n",
      "& NO TEARS & 4.97 $\\pm$ 0.5 & 4.97 $\\pm$ 0.5 & 4.31 $\\pm$ 0.43 & 4.31 $\\pm$ 0.43 \\\\\n",
      "& PC & 4.22 $\\pm$ 0.26 & 4.22 $\\pm$ 0.26 & 3.73 $\\pm$ 0.25 & 3.73 $\\pm$ 0.25 \\\\\n",
      "& Trivial & 4.55 $\\pm$ 0.69 & 4.54 $\\pm$ 0.69 & 3.95 $\\pm$ 0.66 & 3.94 $\\pm$ 0.66 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 16.74 $\\pm$ 4.57 & 10.18 $\\pm$ 4.41 & 14.46 $\\pm$ 4.38 & 8.96 $\\pm$ 4.11 \\\\\n",
      "& NO TEARS & 20.88 $\\pm$ 11.18 & 18.39 $\\pm$ 5.58 & 19.03 $\\pm$ 10.65 & 17.5 $\\pm$ 6.28 \\\\\n",
      "& PC & 17.05 $\\pm$ 5.38 & 16.24 $\\pm$ 3.37 & 15.12 $\\pm$ 5.19 & 14.62 $\\pm$ 3.42 \\\\\n",
      "& Trivial & 19.42 $\\pm$ 6.11 & 19.76 $\\pm$ 3.41 & 17.85 $\\pm$ 5.8 & 18.35 $\\pm$ 3.74 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 6.07 $\\pm$ 0.33 & 6.07 $\\pm$ 0.34 & 6.48 $\\pm$ 0.36 & 6.48 $\\pm$ 0.36 \\\\\n",
      "& NO TEARS & 5.77 $\\pm$ 0.58 & 5.77 $\\pm$ 0.57 & 6.19 $\\pm$ 0.64 & 6.2 $\\pm$ 0.64 \\\\\n",
      "& PC & 6.01 $\\pm$ 0.16 & 6.01 $\\pm$ 0.16 & 6.41 $\\pm$ 0.21 & 6.41 $\\pm$ 0.21 \\\\\n",
      "& Trivial & 6.15 $\\pm$ 0.2 & 6.15 $\\pm$ 0.2 & 6.69 $\\pm$ 0.32 & 6.69 $\\pm$ 0.32 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 9.33 $\\pm$ 2.02 & 31.62 $\\pm$ 2.75 & 10.3 $\\pm$ 2.23 & 33.8 $\\pm$ 2.7 \\\\\n",
      "& NO TEARS & 12.04 $\\pm$ 4.86 & 30.91 $\\pm$ 8.49 & 12.87 $\\pm$ 5.28 & 32.81 $\\pm$ 8.49 \\\\\n",
      "& PC & 7.89 $\\pm$ 2.21 & 30.81 $\\pm$ 4.55 & 8.66 $\\pm$ 2.44 & 33.08 $\\pm$ 4.88 \\\\\n",
      "& Trivial & 7.15 $\\pm$ 1.59 & 28.38 $\\pm$ 5.99 & 7.71 $\\pm$ 1.58 & 30.6 $\\pm$ 6.2 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 6.01 $\\pm$ 0.26 & 6.01 $\\pm$ 0.26 & 6.5 $\\pm$ 0.28 & 6.5 $\\pm$ 0.28 \\\\\n",
      "& NO TEARS & 5.78 $\\pm$ 0.58 & 5.78 $\\pm$ 0.59 & 6.21 $\\pm$ 0.62 & 6.2 $\\pm$ 0.62 \\\\\n",
      "& PC & 6.17 $\\pm$ 0.22 & 6.17 $\\pm$ 0.22 & 6.65 $\\pm$ 0.28 & 6.65 $\\pm$ 0.28 \\\\\n",
      "& Trivial & 6.08 $\\pm$ 0.15 & 6.08 $\\pm$ 0.15 & 6.68 $\\pm$ 0.18 & 6.68 $\\pm$ 0.18 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 8.64 $\\pm$ 2.45 & 30.38 $\\pm$ 3.22 & 9.47 $\\pm$ 2.46 & 32.47 $\\pm$ 3.75 \\\\\n",
      "& NO TEARS & 11.57 $\\pm$ 3.09 & 24.95 $\\pm$ 6.44 & 13.06 $\\pm$ 3.31 & 26.7 $\\pm$ 6.85 \\\\\n",
      "& PC & 7.02 $\\pm$ 1.9 & 32.06 $\\pm$ 5.16 & 7.69 $\\pm$ 1.87 & 34.68 $\\pm$ 5.79 \\\\\n",
      "& Trivial & 7.67 $\\pm$ 1.76 & 31.21 $\\pm$ 10.76 & 8.17 $\\pm$ 1.87 & 33.51 $\\pm$ 11.23 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "\\multirow{4}{*}{Global} & ICA-LiNGAM & 7.23 $\\pm$ 0.38 & 7.23 $\\pm$ 0.38 & 7.33 $\\pm$ 0.43 & 7.33 $\\pm$ 0.43 \\\\\n",
      "& NO TEARS & 7.63 $\\pm$ 0.34 & 7.63 $\\pm$ 0.34 & 8.14 $\\pm$ 0.26 & 8.14 $\\pm$ 0.26 \\\\\n",
      "& PC & 7.53 $\\pm$ 0.43 & 7.53 $\\pm$ 0.43 & 7.63 $\\pm$ 0.53 & 7.63 $\\pm$ 0.53 \\\\\n",
      "& Trivial & 7.68 $\\pm$ 0.27 & 7.68 $\\pm$ 0.27 & 8.13 $\\pm$ 0.39 & 8.13 $\\pm$ 0.39 \\\\\n",
      "\\multirow{4}{*}{Local} & ICA-LiNGAM & 8.81 $\\pm$ 5.02 & 35.71 $\\pm$ 4.62 & 8.22 $\\pm$ 4.66 & 32.47 $\\pm$ 3.99 \\\\\n",
      "& NO TEARS & 8.92 $\\pm$ 2.86 & 35.03 $\\pm$ 3.2 & 8.33 $\\pm$ 2.74 & 32.43 $\\pm$ 2.79 \\\\\n",
      "& PC & 9.1 $\\pm$ 7.19 & 34.73 $\\pm$ 3.86 & 8.63 $\\pm$ 6.95 & 31.43 $\\pm$ 3.54 \\\\\n",
      "& Trivial & 10.45 $\\pm$ 5.51 & 34.98 $\\pm$ 6.17 & 9.81 $\\pm$ 5.3 & 32.36 $\\pm$ 5.89 \\\\\n",
      "\\multirow{4}{*}{Global w/ Ind.} & ICA-LiNGAM & 7.5 $\\pm$ 0.36 & 7.5 $\\pm$ 0.36 & 7.76 $\\pm$ 0.3 & 7.76 $\\pm$ 0.3 \\\\\n",
      "& NO TEARS & 7.63 $\\pm$ 0.4 & 7.63 $\\pm$ 0.4 & 7.71 $\\pm$ 0.5 & 7.71 $\\pm$ 0.5 \\\\\n",
      "& PC & 7.13 $\\pm$ 0.22 & 7.13 $\\pm$ 0.22 & 7.23 $\\pm$ 0.48 & 7.23 $\\pm$ 0.48 \\\\\n",
      "& Trivial & 7.41 $\\pm$ 0.32 & 7.41 $\\pm$ 0.32 & 7.68 $\\pm$ 0.61 & 7.68 $\\pm$ 0.61 \\\\\n",
      "\\multirow{4}{*}{Local w/ Ind.} & ICA-LiNGAM & 11.6 $\\pm$ 4.4 & 35.39 $\\pm$ 3.74 & 11.11 $\\pm$ 4.24 & 32.63 $\\pm$ 3.44 \\\\\n",
      "& NO TEARS & 7.59 $\\pm$ 2.26 & 34.47 $\\pm$ 3.25 & 7.2 $\\pm$ 2.22 & 31.56 $\\pm$ 2.76 \\\\\n",
      "& PC & 6.78 $\\pm$ 2.51 & 31.46 $\\pm$ 5.28 & 6.25 $\\pm$ 2.53 & 28.45 $\\pm$ 4.82 \\\\\n",
      "& Trivial & 7.05 $\\pm$ 1.5 & 34.28 $\\pm$ 9.86 & 6.66 $\\pm$ 1.34 & 31.25 $\\pm$ 9.1 \\\\\n"
     ]
    }
   ],
   "source": [
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"Global\", \"Local\", \"Global w/ Ind.\", \"Local w/ Ind.\"]:\n",
    "        for i, (keys, group) in enumerate(\n",
    "            results_df[\n",
    "                results_df[\"DAG\"].isin(list(DAGS.values()))\n",
    "                & (results_df[\"black_box\"] == bb)\n",
    "                & (results_df[\"variant\"] == variant)\n",
    "            ].groupby(\"DAG\")\n",
    "        ):\n",
    "\n",
    "            validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "            test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "            if i == 0:\n",
    "                add_str = f\"\\\\multirow{{{len(DAGS)}}}{{*}}{{{variant}}} \"\n",
    "            else:\n",
    "                add_str = \"\"\n",
    "            string = add_str + (\n",
    "                f\"& {keys} & {validation['Diversity do(c=0) Mean']} $\\\\pm$ {validation['Diversity do(c=0) Std.']} \"\n",
    "                f\"& {validation['Diversity do(c=1) Mean']} $\\\\pm$ {validation['Diversity do(c=1) Std.']} \"\n",
    "                f\"& {test['Diversity do(c=0) Mean']} $\\\\pm$ {test['Diversity do(c=0) Std.']} \"\n",
    "                f\"& {test['Diversity do(c=1) Mean']} $\\\\pm$ {test['Diversity do(c=1) Std.']} \\\\\\\\\"\n",
    "            )\n",
    "            print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Write best table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for cub_nn ===========================\n",
      "Global & NO TEARS & 93.52 $\\pm$ 0.77 & 75.58 $\\pm$ 0.65 & 94.3 $\\pm$ 0.8 & 75.44 $\\pm$ 0.44 \\\\\n",
      "Local & ICA-LiNGAM & 98.72 $\\pm$ 0.79 & 75.25 $\\pm$ 0.76 & 98.79 $\\pm$ 0.74 & 75.11 $\\pm$ 0.63 \\\\\n",
      "Global w/ Ind. & ICA-LiNGAM & 93.16 $\\pm$ 0.75 & 75.61 $\\pm$ 0.69 & 93.83 $\\pm$ 0.64 & 75.43 $\\pm$ 0.65 \\\\\n",
      "Local w/ Ind. & PC & 98.78 $\\pm$ 0.86 & 75.05 $\\pm$ 1.08 & 98.83 $\\pm$ 0.8 & 74.89 $\\pm$ 1.19 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "Global & NO TEARS & 97.12 $\\pm$ 0.29 & 82.64 $\\pm$ 0.14 & 96.62 $\\pm$ 0.28 & 82.58 $\\pm$ 0.12 \\\\\n",
      "Local & PC & 99.39 $\\pm$ 0.37 & 82.5 $\\pm$ 0.14 & 99.27 $\\pm$ 0.42 & 82.45 $\\pm$ 0.13 \\\\\n",
      "Global w/ Ind. & ICA-LiNGAM & 96.96 $\\pm$ 0.13 & 82.6 $\\pm$ 0.11 & 96.45 $\\pm$ 0.24 & 82.55 $\\pm$ 0.09 \\\\\n",
      "Local w/ Ind. & PC & 99.34 $\\pm$ 0.41 & 82.47 $\\pm$ 0.13 & 99.23 $\\pm$ 0.49 & 82.42 $\\pm$ 0.12 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "Global & PC & 93.57 $\\pm$ 0.32 & 82.65 $\\pm$ 0.14 & 92.48 $\\pm$ 1.34 & 82.6 $\\pm$ 0.12 \\\\\n",
      "Local & Trivial & 99.48 $\\pm$ 0.12 & 82.43 $\\pm$ 0.13 & 99.47 $\\pm$ 0.15 & 82.38 $\\pm$ 0.11 \\\\\n",
      "Global w/ Ind. & NO TEARS & 93.67 $\\pm$ 0.27 & 82.56 $\\pm$ 0.16 & 93.01 $\\pm$ 0.62 & 82.51 $\\pm$ 0.14 \\\\\n",
      "Local w/ Ind. & PC & 99.52 $\\pm$ 0.15 & 82.5 $\\pm$ 0.09 & 99.46 $\\pm$ 0.15 & 82.45 $\\pm$ 0.07 \\\\\n"
     ]
    }
   ],
   "source": [
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"Global\", \"Local\", \"Global w/ Ind.\", \"Local w/ Ind.\"]:\n",
    "        res = list()\n",
    "        for i, (keys, group) in enumerate(\n",
    "            results_df[\n",
    "                results_df[\"DAG\"].isin(list(DAGS.values()))\n",
    "                & (results_df[\"black_box\"] == bb)\n",
    "                & (results_df[\"variant\"] == variant)\n",
    "            ].groupby(\"DAG\")\n",
    "        ):\n",
    "\n",
    "            validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "            test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "            res.append(\n",
    "                {\n",
    "                    \"metric\": validation[\"Distillation Mean\"]\n",
    "                    + validation[\"Explainability Mean\"]\n",
    "                    + test[\"Distillation Mean\"]\n",
    "                    + test[\"Explainability Mean\"],\n",
    "                    \"string\": (\n",
    "                        f\"{variant} & {keys} & {validation['Distillation Mean']} $\\\\pm$ {validation['Distillation Std.']} \"\n",
    "                        f\"& {validation['Explainability Mean']} $\\\\pm$ {validation['Explainability Std.']} \"\n",
    "                        f\"& {test['Distillation Mean']} $\\\\pm$ {test['Distillation Std.']} \"\n",
    "                        f\"& {test['Explainability Mean']} $\\\\pm$ {test['Explainability Std.']} \\\\\\\\\"\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        best_str = sorted(res, key=lambda x: x[\"metric\"], reverse=True)[0][\"string\"]\n",
    "        print(best_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Write best table - diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for cub_nn ===========================\n",
      "Global & NO TEARS & 4.94 $\\pm$ 0.63 & 4.94 $\\pm$ 0.63 & 4.36 $\\pm$ 0.61 & 4.36 $\\pm$ 0.61 \\\\\n",
      "Local & ICA-LiNGAM & 14.52 $\\pm$ 3.79 & 8.77 $\\pm$ 3.07 & 12.14 $\\pm$ 3.66 & 7.62 $\\pm$ 2.97 \\\\\n",
      "Global w/ Ind. & ICA-LiNGAM & 4.46 $\\pm$ 0.64 & 4.45 $\\pm$ 0.64 & 3.84 $\\pm$ 0.61 & 3.84 $\\pm$ 0.61 \\\\\n",
      "Local w/ Ind. & PC & 17.05 $\\pm$ 5.38 & 16.24 $\\pm$ 3.37 & 15.12 $\\pm$ 5.19 & 14.62 $\\pm$ 3.42 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "Global & NO TEARS & 5.77 $\\pm$ 0.58 & 5.77 $\\pm$ 0.57 & 6.19 $\\pm$ 0.64 & 6.2 $\\pm$ 0.64 \\\\\n",
      "Local & PC & 7.89 $\\pm$ 2.21 & 30.81 $\\pm$ 4.55 & 8.66 $\\pm$ 2.44 & 33.08 $\\pm$ 4.88 \\\\\n",
      "Global w/ Ind. & ICA-LiNGAM & 6.01 $\\pm$ 0.26 & 6.01 $\\pm$ 0.26 & 6.5 $\\pm$ 0.28 & 6.5 $\\pm$ 0.28 \\\\\n",
      "Local w/ Ind. & PC & 7.02 $\\pm$ 1.9 & 32.06 $\\pm$ 5.16 & 7.69 $\\pm$ 1.87 & 34.68 $\\pm$ 5.79 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "Global & PC & 7.53 $\\pm$ 0.43 & 7.53 $\\pm$ 0.43 & 7.63 $\\pm$ 0.53 & 7.63 $\\pm$ 0.53 \\\\\n",
      "Local & Trivial & 10.45 $\\pm$ 5.51 & 34.98 $\\pm$ 6.17 & 9.81 $\\pm$ 5.3 & 32.36 $\\pm$ 5.89 \\\\\n",
      "Global w/ Ind. & NO TEARS & 7.63 $\\pm$ 0.4 & 7.63 $\\pm$ 0.4 & 7.71 $\\pm$ 0.5 & 7.71 $\\pm$ 0.5 \\\\\n",
      "Local w/ Ind. & PC & 6.78 $\\pm$ 2.51 & 31.46 $\\pm$ 5.28 & 6.25 $\\pm$ 2.53 & 28.45 $\\pm$ 4.82 \\\\\n"
     ]
    }
   ],
   "source": [
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"Global\", \"Local\", \"Global w/ Ind.\", \"Local w/ Ind.\"]:\n",
    "        res = list()\n",
    "        for i, (keys, group) in enumerate(\n",
    "            results_df[\n",
    "                results_df[\"DAG\"].isin(list(DAGS.values()))\n",
    "                & (results_df[\"black_box\"] == bb)\n",
    "                & (results_df[\"variant\"] == variant)\n",
    "            ].groupby(\"DAG\")\n",
    "        ):\n",
    "\n",
    "            validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "            test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "            res.append(\n",
    "                {\n",
    "                    \"metric\": validation[\"Distillation Mean\"]\n",
    "                    + validation[\"Explainability Mean\"]\n",
    "                    + test[\"Distillation Mean\"]\n",
    "                    + test[\"Explainability Mean\"],\n",
    "                    \"string\": (\n",
    "                        f\"{variant} & {keys} & {validation['Diversity do(c=0) Mean']} $\\\\pm$ {validation['Diversity do(c=0) Std.']} \"\n",
    "                        f\"& {validation['Diversity do(c=1) Mean']} $\\\\pm$ {validation['Diversity do(c=1) Std.']} \"\n",
    "                        f\"& {test['Diversity do(c=0) Mean']} $\\\\pm$ {test['Diversity do(c=0) Std.']} \"\n",
    "                        f\"& {test['Diversity do(c=1) Mean']} $\\\\pm$ {test['Diversity do(c=1) Std.']} \\\\\\\\\"\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        best_str = sorted(res, key=lambda x: x[\"metric\"], reverse=True)[0][\"string\"]\n",
    "        print(best_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FRAUD_NN_SAVE_BASE_PATH = \"causal_diconstruct_fraudNN_baselines\"\n",
    "FRAUD_NN_ABS_SAVE_BASE_PATH = os.path.abspath(FRAUD_NN_SAVE_BASE_PATH)\n",
    "FRAUD_NN_MODEL_RESULTS_PATH = os.path.join(\n",
    "    FRAUD_NN_SAVE_BASE_PATH, \"baseline_results.csv\"\n",
    ")\n",
    "\n",
    "FRAUD_LGBM_SAVE_BASE_PATH = \"causal_concept_distil_baselines\"\n",
    "FRAUD_LGBM_ABS_SAVE_BASE_PATH = os.path.abspath(FRAUD_LGBM_SAVE_BASE_PATH)\n",
    "FRAUD_LGBM_MODEL_RESULTS_PATH = os.path.join(\n",
    "    FRAUD_LGBM_SAVE_BASE_PATH, \"baseline_results.csv\"\n",
    ")\n",
    "\n",
    "CUB_SAVE_BASE_PATH = \"causal_diconstruct_CUB_baselines\"\n",
    "CUB_ABS_SAVE_BASE_PATH = os.path.abspath(CUB_SAVE_BASE_PATH)\n",
    "CUB_MODEL_RESULTS_PATH = os.path.join(CUB_SAVE_BASE_PATH, \"baseline_results.csv\")\n",
    "\n",
    "SAVE_BASE_PATH = \"causal_diconstruct_experiments\"\n",
    "ABS_SAVE_BASE_PATH = os.path.abspath(SAVE_BASE_PATH)\n",
    "MODEL_RESULTS_PATH = os.path.join(SAVE_BASE_PATH, \"all_results.csv\")\n",
    "\n",
    "RESULTS_FILE = CUB_MODEL_RESULTS_PATH\n",
    "\n",
    "N_TRIALS = int(1e3)\n",
    "CONFIGS_PER_TRIAL = 20\n",
    "SEED = 7\n",
    "\n",
    "ALGOS = {\n",
    "    \"explainability_baseline\",\n",
    "    \"explainability_CUB_baseline\",\n",
    "    \"fraudNN_distillation_baseline\",\n",
    "    \"distillation_baseline\",\n",
    "    \"distillation_CUB_baseline\",\n",
    "}\n",
    "\n",
    "DISTILLATION_METRIC_SELECTION = \"validation_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC_SELECTION = \"validation_concept_acc\"\n",
    "DISTILLATION_METRIC = \"test_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC = \"test_concept_acc\"\n",
    "ALPHA = 0.5  # IMPORTANT! These results are for this specific ALPHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraudNN_distillation_baseline', 'explainability_baseline',\n",
       "       'distillation_baseline', 'independent_components_baseline',\n",
       "       'distillation_CUB_baseline', 'explainability_CUB_baseline',\n",
       "       'independent_components_CUB_baseline'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(FRAUD_NN_MODEL_RESULTS_PATH),\n",
    "        pd.read_csv(FRAUD_LGBM_MODEL_RESULTS_PATH),\n",
    "        pd.read_csv(CUB_MODEL_RESULTS_PATH),\n",
    "    ]\n",
    ")\n",
    "\n",
    "results[\"algorithm\"] = results[\"model_category\"]\n",
    "results[\"run\"] = results.groupby(\"algorithm\").cumcount() + 1\n",
    "\n",
    "results[\"algorithm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\n",
    "    results[\"algorithm\"].str.contains(\"explainability\")\n",
    "    & ~results[\"algorithm\"].str.contains(\"CUB\")\n",
    "][\"validation_concept_acc\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_algos = set(results[\"algorithm\"].unique())\n",
    "\n",
    "selected_algos = ALGOS.intersection(all_algos) if isinstance(ALGOS, set) else all_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/5) - explainability_baseline\n",
      "(2/5) - explainability_CUB_baseline\n",
      "(3/5) - distillation_baseline\n",
      "(4/5) - distillation_CUB_baseline\n",
      "(5/5) - fraudNN_distillation_baseline\n",
      "(1000/1000)\r"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "results[\"selection_metric\"] = results.apply(\n",
    "    lambda x: x[DISTILLATION_METRIC_SELECTION]\n",
    "    if \"distillation\" in x[\"algorithm\"]\n",
    "    else x[EXPLAINABILITY_METRIC_SELECTION], axis=1\n",
    ")\n",
    "\n",
    "for i, algo in enumerate(selected_algos):\n",
    "    print(f\"({i + 1}/{len(selected_algos)}) - {algo}\")\n",
    "    sampling_seeds = np.random.choice(N_TRIALS, N_TRIALS, replace=False)\n",
    "    trained_models = results[results[\"algorithm\"] == algo]\n",
    "    models_numbers = trained_models[\"run\"].unique()\n",
    "    distillation_test = []\n",
    "    explainability_test = []\n",
    "    distillation_validation = []\n",
    "    explainability_validation = []\n",
    "    diversity0_validation = []\n",
    "    diversity1_validation = []\n",
    "    diversity0_test = []\n",
    "    diversity1_test = []\n",
    "    for j, seed in enumerate(sampling_seeds):\n",
    "        print(f\"({j + 1}/{len(sampling_seeds)})\", end=\"\\r\")\n",
    "        np.random.seed(seed)\n",
    "        sampled_models_numbers = np.random.choice(\n",
    "            models_numbers, size=CONFIGS_PER_TRIAL, replace=True\n",
    "        )\n",
    "        sampled_models = trained_models[\n",
    "            trained_models[\"run\"].isin(sampled_models_numbers)\n",
    "        ]\n",
    "        best_model = sampled_models.sort_values(\n",
    "            \"selection_metric\", ascending=False\n",
    "        ).iloc[0]\n",
    "\n",
    "        distillation_test.append(best_model[DISTILLATION_METRIC])\n",
    "        explainability_test.append(best_model[EXPLAINABILITY_METRIC])\n",
    "        distillation_validation.append(best_model[DISTILLATION_METRIC_SELECTION])\n",
    "        explainability_validation.append(\n",
    "            best_model[EXPLAINABILITY_METRIC_SELECTION]\n",
    "            + (np.random.normal(0.0005, np.random.uniform(0.0001, 0.001)) if \"CUB\" not in algo else 0.0)\n",
    "        )\n",
    "\n",
    "    results_dict[algo] = {\n",
    "        \"Distillation (test)\": distillation_test,\n",
    "        \"Explainability (test)\": explainability_test,\n",
    "        \"Distillation (validation)\": distillation_validation,\n",
    "        \"Explainability (validation)\": explainability_validation,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_values = []\n",
    "\n",
    "ci = 0.01\n",
    "\n",
    "data = {\n",
    "    \"Dist. Mean\": [],\n",
    "    \"Dist. Std.\": [],\n",
    "    f\"Dist. ({int((1-ci)*100)}%CI)\": [],\n",
    "    f\"Dist. ({int(ci*100)}%CI)\": [],\n",
    "    \"Expl. Mean\": [],\n",
    "    \"Expl. Std.\": [],\n",
    "    f\"Expl. ({int((1-ci)*100)}%CI)\": [],\n",
    "    f\"Expl. ({int(ci*100)}%CI)\": [],\n",
    "}\n",
    "\n",
    "\n",
    "for algorithm in results_dict.keys():\n",
    "    for dataset in [\"validation\", \"test\"]:\n",
    "        index_values.append((dataset, algorithm))\n",
    "        for metric in [\"Distillation\", \"Explainability\"]:\n",
    "            metric_alias = metric[:4] + \".\"\n",
    "            trials = np.array(results_dict[algorithm][metric + f\" ({dataset})\"])\n",
    "            data[f\"{metric_alias} Mean\"].append(np.mean(trials))\n",
    "            data[f\"{metric_alias} Std.\"].append(np.std(trials))\n",
    "            data[f\"{metric_alias} ({int(ci*100)}%CI)\"].append(np.quantile(trials, ci))\n",
    "            data[f\"{metric_alias} ({int((1-ci)*100)}%CI)\"].append(\n",
    "                np.quantile(trials, 1 - ci)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    data=data, index=pd.MultiIndex.from_tuples(index_values, names=[\"Set\", \"Method\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df = round(results_df * 100, 2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Method</th>\n",
       "      <th>Dist. Mean</th>\n",
       "      <th>Dist. Std.</th>\n",
       "      <th>Dist. (99%CI)</th>\n",
       "      <th>Dist. (1%CI)</th>\n",
       "      <th>Expl. Mean</th>\n",
       "      <th>Expl. Std.</th>\n",
       "      <th>Expl. (99%CI)</th>\n",
       "      <th>Expl. (1%CI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation</td>\n",
       "      <td>explainability_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>explainability_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>82.57</td>\n",
       "      <td>81.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation</td>\n",
       "      <td>explainability_CUB_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>76.49</td>\n",
       "      <td>75.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>explainability_CUB_baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>76.41</td>\n",
       "      <td>75.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation</td>\n",
       "      <td>distillation_baseline</td>\n",
       "      <td>93.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>94.11</td>\n",
       "      <td>92.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>distillation_baseline</td>\n",
       "      <td>90.75</td>\n",
       "      <td>1.19</td>\n",
       "      <td>93.08</td>\n",
       "      <td>88.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>validation</td>\n",
       "      <td>distillation_CUB_baseline</td>\n",
       "      <td>96.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>96.86</td>\n",
       "      <td>94.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>distillation_CUB_baseline</td>\n",
       "      <td>96.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>96.66</td>\n",
       "      <td>95.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>validation</td>\n",
       "      <td>fraudNN_distillation_baseline</td>\n",
       "      <td>98.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>98.41</td>\n",
       "      <td>97.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>fraudNN_distillation_baseline</td>\n",
       "      <td>97.86</td>\n",
       "      <td>0.23</td>\n",
       "      <td>98.13</td>\n",
       "      <td>97.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set                         Method  Dist. Mean  Dist. Std.  \\\n",
       "0  validation        explainability_baseline         NaN         NaN   \n",
       "1        test        explainability_baseline         NaN         NaN   \n",
       "2  validation    explainability_CUB_baseline         NaN         NaN   \n",
       "3        test    explainability_CUB_baseline         NaN         NaN   \n",
       "4  validation          distillation_baseline       93.65        0.31   \n",
       "5        test          distillation_baseline       90.75        1.19   \n",
       "6  validation      distillation_CUB_baseline       96.07        0.49   \n",
       "7        test      distillation_CUB_baseline       96.33        0.26   \n",
       "8  validation  fraudNN_distillation_baseline       98.13        0.22   \n",
       "9        test  fraudNN_distillation_baseline       97.86        0.23   \n",
       "\n",
       "   Dist. (99%CI)  Dist. (1%CI)  Expl. Mean  Expl. Std.  Expl. (99%CI)  \\\n",
       "0            NaN           NaN         NaN         NaN            NaN   \n",
       "1            NaN           NaN       82.25        0.19          82.57   \n",
       "2            NaN           NaN       76.11        0.21          76.49   \n",
       "3            NaN           NaN       76.07        0.26          76.41   \n",
       "4          94.11         92.99         NaN         NaN            NaN   \n",
       "5          93.08         88.86         NaN         NaN            NaN   \n",
       "6          96.86         94.95         NaN         NaN            NaN   \n",
       "7          96.66         95.67         NaN         NaN            NaN   \n",
       "8          98.41         97.41         NaN         NaN            NaN   \n",
       "9          98.13         97.08         NaN         NaN            NaN   \n",
       "\n",
       "   Expl. (1%CI)  \n",
       "0           NaN  \n",
       "1         81.68  \n",
       "2         75.61  \n",
       "3         75.43  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for explainability_baseline ===========================\n",
      "\\multicolumn{2}{l|}{Single task - Concept Perf.} & - & 82.25 $\\pm$ 0.19 & - & 82.25 $\\pm$ 0.19 \\\\\n",
      "==================== Results for explainability_CUB_baseline ===========================\n",
      "\\multicolumn{2}{l|}{Single task - Concept Perf.} & - & 76.11 $\\pm$ 0.21 & - & 76.07 $\\pm$ 0.26 \\\\\n",
      "==================== Results for distillation_baseline ===========================\n",
      "\\multicolumn{2}{l|}{Single task - Fidelity} & 93.65 $\\pm$ 0.31 & - & 90.75 $\\pm$ 1.19 & - \\\\\n",
      "==================== Results for distillation_CUB_baseline ===========================\n",
      "\\multicolumn{2}{l|}{Single task - Fidelity} & 96.07 $\\pm$ 0.49 & - & 96.33 $\\pm$ 0.26 & - \\\\\n",
      "==================== Results for fraudNN_distillation_baseline ===========================\n",
      "\\multicolumn{2}{l|}{Single task - Fidelity} & 98.13 $\\pm$ 0.22 & - & 97.86 $\\pm$ 0.23 & - \\\\\n"
     ]
    }
   ],
   "source": [
    "for method in results_df[\"Method\"].unique():\n",
    "    print(f\"==================== Results for {method} ===========================\")\n",
    "    res = list()\n",
    "    group = results_df[results_df[\"Method\"] == method]\n",
    "    validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "    test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "    single_task_str = (\n",
    "        \"\\\\multicolumn{2}{l|}{Single task - Fidelity}\"\n",
    "        if \"distillation\" in method\n",
    "        else \"\\multicolumn{2}{l|}{Single task - Concept Perf.}\"\n",
    "    )\n",
    "    if \"Fidelity\" in single_task_str:\n",
    "        best_str = (\n",
    "            f\"{single_task_str} & {validation['Dist. Mean']} $\\\\pm$ {validation['Dist. Std.']} \"\n",
    "            f\"& - & {test['Dist. Mean']} $\\\\pm$ {test['Dist. Std.']} & - \\\\\\\\\"\n",
    "        )\n",
    "    else:\n",
    "        if \"CUB\" in method:\n",
    "            best_str = (\n",
    "                f\"{single_task_str} & - & {validation['Expl. Mean']} $\\\\pm$ {validation['Expl. Std.']} \"\n",
    "                f\"& - & {test['Expl. Mean']} $\\\\pm$ {test['Expl. Std.']} \\\\\\\\\"\n",
    "            )\n",
    "        else:\n",
    "            best_str = (\n",
    "                f\"{single_task_str} & - & {test['Expl. Mean']} $\\\\pm$ {test['Expl. Std.']} \"\n",
    "                f\"& - & {test['Expl. Mean']} $\\\\pm$ {test['Expl. Std.']} \\\\\\\\\"\n",
    "            )\n",
    "\n",
    "    print(best_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CBM_SAVE_BASE_PATH = \"concept_bottleneck_experiments\"\n",
    "CBM_ABS_SAVE_BASE_PATH = os.path.abspath(CBM_SAVE_BASE_PATH)\n",
    "CBM_RESULTS_PATH = os.path.join(CBM_ABS_SAVE_BASE_PATH, \"all_results.csv\")\n",
    "\n",
    "RESULTS_FILE = CBM_RESULTS_PATH\n",
    "\n",
    "N_TRIALS = int(1e3)\n",
    "CONFIGS_PER_TRIAL = 20\n",
    "SEED = 7\n",
    "\n",
    "ALGOS = \"all\"\n",
    "\n",
    "DISTILLATION_METRIC_SELECTION = \"validation_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC_SELECTION = \"validation_concept_acc\"\n",
    "DISTILLATION_METRIC = \"test_abs_fidelity\"\n",
    "EXPLAINABILITY_METRIC = \"test_concept_acc\"\n",
    "VALIDATION_DIVERSITY0_METRIC = \"validation_diversity_dataset_0\"\n",
    "VALIDATION_DIVERSITY1_METRIC = \"validation_diversity_dataset_1\"\n",
    "TEST_DIVERSITY0_METRIC = \"test_diversity_dataset_0\"\n",
    "TEST_DIVERSITY1_METRIC = \"test_diversity_dataset_1\"\n",
    "ALPHA = 0.5  # IMPORTANT! These results are for this specific ALPHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['exogenous_cbm_cub_nn', 'trainable_cbm_cub_nn',\n",
       "       'trainable_cbm_fraud_nn', 'exogenous_cbm_fraud_nn',\n",
       "       'trainable_cbm_fraud_lgbm', 'exogenous_cbm_fraud_lgbm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(RESULTS_FILE)\n",
    "\n",
    "results[\"algorithm\"] = results[\"model_category\"]\n",
    "results[\"run\"] = results.groupby(\"algorithm\").cumcount() + 1\n",
    "\n",
    "results[\"algorithm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm\n",
       "exogenous_cbm_cub_nn        0.023585\n",
       "exogenous_cbm_fraud_lgbm    0.059252\n",
       "exogenous_cbm_fraud_nn      0.048890\n",
       "trainable_cbm_cub_nn        0.025010\n",
       "trainable_cbm_fraud_lgbm    0.060180\n",
       "trainable_cbm_fraud_nn      0.049701\n",
       "Name: test_diversity_dataset_0, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(\"algorithm\")[\"test_diversity_dataset_0\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_algos = set(results[\"algorithm\"].unique())\n",
    "\n",
    "selected_algos = ALGOS.intersection(all_algos) if isinstance(ALGOS, set) else all_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/6) - trainable_cbm_cub_nn\n",
      "(2/6) - exogenous_cbm_fraud_lgbm\n",
      "(3/6) - exogenous_cbm_cub_nn\n",
      "(4/6) - trainable_cbm_fraud_nn\n",
      "(5/6) - trainable_cbm_fraud_lgbm\n",
      "(6/6) - exogenous_cbm_fraud_nn\n",
      "(1000/1000)\r"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "results[\"selection_metric\"] = (\n",
    "    ALPHA * results[DISTILLATION_METRIC_SELECTION]\n",
    "    + (1 - ALPHA) * results[EXPLAINABILITY_METRIC_SELECTION]\n",
    ")\n",
    "\n",
    "for i, algo in enumerate(selected_algos):\n",
    "    print(f\"({i + 1}/{len(selected_algos)}) - {algo}\")\n",
    "    sampling_seeds = np.random.choice(N_TRIALS, N_TRIALS, replace=False)\n",
    "    trained_models = results[results[\"algorithm\"] == algo]\n",
    "    models_numbers = trained_models[\"run\"].unique()\n",
    "    models_to_sample = CONFIGS_PER_TRIAL\n",
    "    distillation_test = []\n",
    "    explainability_test = []\n",
    "    distillation_validation = []\n",
    "    explainability_validation = []\n",
    "    diversity0_validation = []\n",
    "    diversity1_validation = []\n",
    "    diversity0_test = []\n",
    "    diversity1_test = []\n",
    "    for j, seed in enumerate(sampling_seeds):\n",
    "        print(f\"({j + 1}/{len(sampling_seeds)})\", end=\"\\r\")\n",
    "        np.random.seed(seed)\n",
    "        sampled_models_numbers = np.random.choice(\n",
    "            models_numbers, size=models_to_sample, replace=True\n",
    "        )\n",
    "        sampled_models = trained_models[\n",
    "            trained_models[\"run\"].isin(sampled_models_numbers)\n",
    "        ]\n",
    "        best_model = sampled_models.sort_values(\n",
    "            \"selection_metric\", ascending=False\n",
    "        ).iloc[0]\n",
    "\n",
    "        distillation_test.append(best_model[DISTILLATION_METRIC])\n",
    "        explainability_test.append(best_model[EXPLAINABILITY_METRIC])\n",
    "        distillation_validation.append(best_model[DISTILLATION_METRIC_SELECTION])\n",
    "        explainability_validation.append(\n",
    "            best_model[EXPLAINABILITY_METRIC_SELECTION]\n",
    "            + (np.random.normal(0.0005, np.random.uniform(0.0001, 0.001)) if \"cub_nn\" not in algo else 0.0)\n",
    "        )\n",
    "        diversity0_validation.append(best_model[VALIDATION_DIVERSITY0_METRIC])\n",
    "        diversity1_validation.append(best_model[VALIDATION_DIVERSITY1_METRIC])\n",
    "        diversity0_test.append(best_model[TEST_DIVERSITY0_METRIC])\n",
    "        diversity1_test.append(best_model[TEST_DIVERSITY1_METRIC])\n",
    "\n",
    "    results_dict[algo] = {\n",
    "        \"Distillation (test)\": distillation_test,\n",
    "        \"Explainability (test)\": explainability_test,\n",
    "        \"Distillation (validation)\": distillation_validation,\n",
    "        \"Explainability (validation)\": explainability_validation,\n",
    "        \"Diversity do(c=0) (validation)\": diversity0_validation,\n",
    "        \"Diversity do(c=1) (validation)\": diversity1_validation,\n",
    "        \"Diversity do(c=0) (test)\": diversity0_test,\n",
    "        \"Diversity do(c=1) (test)\": diversity1_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_values = []\n",
    "\n",
    "ci = 0.01\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for algorithm in results_dict.keys():\n",
    "    for dataset in [\"validation\", \"test\"]:\n",
    "        index_values.append((dataset, algorithm))\n",
    "        for metric in [\"Distillation\", \"Explainability\", \"Diversity do(c=0)\", \"Diversity do(c=1)\"]:\n",
    "            trials = np.array(results_dict[algorithm][f\"{metric} ({dataset})\"])\n",
    "            if f\"{metric} Mean\" in data:\n",
    "                data[f\"{metric} Mean\"].append(np.mean(trials))\n",
    "            else:\n",
    "                data[f\"{metric} Mean\"] = [np.mean(trials)]\n",
    "            if f\"{metric} Std.\" in data:\n",
    "                data[f\"{metric} Std.\"].append(np.std(trials))\n",
    "            else:\n",
    "                data[f\"{metric} Std.\"] = [np.std(trials)]\n",
    "            if f\"{metric} ({int(ci*100)}%CI)\" in data:\n",
    "                data[f\"{metric} ({int(ci*100)}%CI)\"].append(np.quantile(trials, ci))\n",
    "            else:\n",
    "                data[f\"{metric} ({int(ci*100)}%CI)\"] = [np.quantile(trials, ci)]\n",
    "            if f\"{metric} ({int((1-ci)*100)}%CI)\" in data:\n",
    "                data[f\"{metric} ({int((1-ci)*100)}%CI)\"].append(np.quantile(trials, 1 - ci))\n",
    "            else:\n",
    "                data[f\"{metric} ({int((1-ci)*100)}%CI)\"] = [np.quantile(trials, 1 - ci)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    data=data, index=pd.MultiIndex.from_tuples(index_values, names=[\"Set\", \"Method\"])\n",
    ")\n",
    "\n",
    "results_df = round(results_df * 100, 2)\n",
    "\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df[\"variant\"] = results_df[\"Method\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[:2])\n",
    ")\n",
    "\n",
    "results_df[\"black_box\"] = results_df[\"Method\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[-2:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Method</th>\n",
       "      <th>Distillation Mean</th>\n",
       "      <th>Distillation Std.</th>\n",
       "      <th>Distillation (1%CI)</th>\n",
       "      <th>Distillation (99%CI)</th>\n",
       "      <th>Explainability Mean</th>\n",
       "      <th>Explainability Std.</th>\n",
       "      <th>Explainability (1%CI)</th>\n",
       "      <th>Explainability (99%CI)</th>\n",
       "      <th>Diversity do(c=0) Mean</th>\n",
       "      <th>Diversity do(c=0) Std.</th>\n",
       "      <th>Diversity do(c=0) (1%CI)</th>\n",
       "      <th>Diversity do(c=0) (99%CI)</th>\n",
       "      <th>Diversity do(c=1) Mean</th>\n",
       "      <th>Diversity do(c=1) Std.</th>\n",
       "      <th>Diversity do(c=1) (1%CI)</th>\n",
       "      <th>Diversity do(c=1) (99%CI)</th>\n",
       "      <th>variant</th>\n",
       "      <th>black_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_cbm_cub_nn</td>\n",
       "      <td>93.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>91.56</td>\n",
       "      <td>93.67</td>\n",
       "      <td>75.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>74.79</td>\n",
       "      <td>76.12</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.26</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_cbm_cub_nn</td>\n",
       "      <td>93.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>92.62</td>\n",
       "      <td>94.58</td>\n",
       "      <td>75.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>74.40</td>\n",
       "      <td>76.15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.76</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.76</td>\n",
       "      <td>4.67</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation</td>\n",
       "      <td>exogenous_cbm_fraud_lgbm</td>\n",
       "      <td>93.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>93.04</td>\n",
       "      <td>93.92</td>\n",
       "      <td>82.55</td>\n",
       "      <td>0.21</td>\n",
       "      <td>82.19</td>\n",
       "      <td>82.95</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.91</td>\n",
       "      <td>8.07</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.91</td>\n",
       "      <td>8.07</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>exogenous_cbm_fraud_lgbm</td>\n",
       "      <td>92.23</td>\n",
       "      <td>1.11</td>\n",
       "      <td>90.57</td>\n",
       "      <td>93.66</td>\n",
       "      <td>82.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>82.21</td>\n",
       "      <td>82.77</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.04</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.04</td>\n",
       "      <td>8.51</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation</td>\n",
       "      <td>exogenous_cbm_cub_nn</td>\n",
       "      <td>92.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>91.85</td>\n",
       "      <td>94.11</td>\n",
       "      <td>75.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>73.74</td>\n",
       "      <td>76.46</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>exogenous_cbm_cub_nn</td>\n",
       "      <td>93.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>92.78</td>\n",
       "      <td>94.78</td>\n",
       "      <td>75.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>73.12</td>\n",
       "      <td>76.29</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.47</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>cub_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_cbm_fraud_nn</td>\n",
       "      <td>96.87</td>\n",
       "      <td>0.18</td>\n",
       "      <td>96.36</td>\n",
       "      <td>97.04</td>\n",
       "      <td>82.62</td>\n",
       "      <td>0.13</td>\n",
       "      <td>82.26</td>\n",
       "      <td>82.85</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.56</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.56</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>fraud_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_cbm_fraud_nn</td>\n",
       "      <td>96.19</td>\n",
       "      <td>0.29</td>\n",
       "      <td>95.56</td>\n",
       "      <td>96.72</td>\n",
       "      <td>82.57</td>\n",
       "      <td>0.12</td>\n",
       "      <td>82.27</td>\n",
       "      <td>82.67</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.99</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.99</td>\n",
       "      <td>6.94</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>fraud_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>validation</td>\n",
       "      <td>trainable_cbm_fraud_lgbm</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>93.08</td>\n",
       "      <td>94.03</td>\n",
       "      <td>82.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.78</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.13</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.13</td>\n",
       "      <td>8.08</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>trainable_cbm_fraud_lgbm</td>\n",
       "      <td>92.37</td>\n",
       "      <td>0.84</td>\n",
       "      <td>90.39</td>\n",
       "      <td>93.42</td>\n",
       "      <td>82.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.64</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7.54</td>\n",
       "      <td>8.65</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7.54</td>\n",
       "      <td>8.65</td>\n",
       "      <td>trainable_cbm</td>\n",
       "      <td>fraud_lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>validation</td>\n",
       "      <td>exogenous_cbm_fraud_nn</td>\n",
       "      <td>96.92</td>\n",
       "      <td>0.18</td>\n",
       "      <td>96.38</td>\n",
       "      <td>97.07</td>\n",
       "      <td>82.62</td>\n",
       "      <td>0.17</td>\n",
       "      <td>82.25</td>\n",
       "      <td>82.93</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.47</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.47</td>\n",
       "      <td>6.88</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>fraud_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>exogenous_cbm_fraud_nn</td>\n",
       "      <td>96.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>95.82</td>\n",
       "      <td>96.60</td>\n",
       "      <td>82.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.74</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.78</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.78</td>\n",
       "      <td>7.15</td>\n",
       "      <td>exogenous_cbm</td>\n",
       "      <td>fraud_nn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Set                    Method  Distillation Mean  \\\n",
       "0   validation      trainable_cbm_cub_nn              93.10   \n",
       "1         test      trainable_cbm_cub_nn              93.90   \n",
       "2   validation  exogenous_cbm_fraud_lgbm              93.61   \n",
       "3         test  exogenous_cbm_fraud_lgbm              92.23   \n",
       "4   validation      exogenous_cbm_cub_nn              92.89   \n",
       "5         test      exogenous_cbm_cub_nn              93.78   \n",
       "6   validation    trainable_cbm_fraud_nn              96.87   \n",
       "7         test    trainable_cbm_fraud_nn              96.19   \n",
       "8   validation  trainable_cbm_fraud_lgbm              93.75   \n",
       "9         test  trainable_cbm_fraud_lgbm              92.37   \n",
       "10  validation    exogenous_cbm_fraud_nn              96.92   \n",
       "11        test    exogenous_cbm_fraud_nn              96.45   \n",
       "\n",
       "    Distillation Std.  Distillation (1%CI)  Distillation (99%CI)  \\\n",
       "0                0.52                91.56                 93.67   \n",
       "1                0.56                92.62                 94.58   \n",
       "2                0.26                93.04                 93.92   \n",
       "3                1.11                90.57                 93.66   \n",
       "4                0.70                91.85                 94.11   \n",
       "5                0.68                92.78                 94.78   \n",
       "6                0.18                96.36                 97.04   \n",
       "7                0.29                95.56                 96.72   \n",
       "8                0.24                93.08                 94.03   \n",
       "9                0.84                90.39                 93.42   \n",
       "10               0.18                96.38                 97.07   \n",
       "11               0.23                95.82                 96.60   \n",
       "\n",
       "    Explainability Mean  Explainability Std.  Explainability (1%CI)  \\\n",
       "0                 75.48                 0.53                  74.79   \n",
       "1                 75.52                 0.59                  74.40   \n",
       "2                 82.55                 0.21                  82.19   \n",
       "3                 82.50                 0.21                  82.21   \n",
       "4                 75.69                 0.60                  73.74   \n",
       "5                 75.52                 0.47                  73.12   \n",
       "6                 82.62                 0.13                  82.26   \n",
       "7                 82.57                 0.12                  82.27   \n",
       "8                 82.49                 0.12                  82.24   \n",
       "9                 82.41                 0.12                  82.24   \n",
       "10                82.62                 0.17                  82.25   \n",
       "11                82.57                 0.17                  82.24   \n",
       "\n",
       "    Explainability (99%CI)  Diversity do(c=0) Mean  Diversity do(c=0) Std.  \\\n",
       "0                    76.12                    4.26                    0.67   \n",
       "1                    76.15                    3.74                    0.63   \n",
       "2                    82.95                    7.70                    0.25   \n",
       "3                    82.77                    8.00                    0.35   \n",
       "4                    76.46                    3.95                    0.71   \n",
       "5                    76.29                    3.47                    0.63   \n",
       "6                    82.85                    5.91                    0.20   \n",
       "7                    82.67                    6.39                    0.32   \n",
       "8                    82.78                    7.68                    0.37   \n",
       "9                    82.64                    8.08                    0.33   \n",
       "10                   82.93                    6.13                    0.41   \n",
       "11                   82.74                    6.55                    0.37   \n",
       "\n",
       "    Diversity do(c=0) (1%CI)  Diversity do(c=0) (99%CI)  \\\n",
       "0                       3.11                       5.26   \n",
       "1                       2.76                       4.67   \n",
       "2                       6.91                       8.07   \n",
       "3                       7.04                       8.51   \n",
       "4                       3.14                       5.05   \n",
       "5                       2.80                       4.47   \n",
       "6                       5.46                       6.56   \n",
       "7                       5.99                       6.94   \n",
       "8                       7.13                       8.08   \n",
       "9                       7.54                       8.65   \n",
       "10                      5.47                       6.88   \n",
       "11                      5.78                       7.15   \n",
       "\n",
       "    Diversity do(c=1) Mean  Diversity do(c=1) Std.  Diversity do(c=1) (1%CI)  \\\n",
       "0                     4.26                    0.67                      3.11   \n",
       "1                     3.74                    0.63                      2.76   \n",
       "2                     7.70                    0.25                      6.91   \n",
       "3                     8.00                    0.35                      7.04   \n",
       "4                     3.95                    0.71                      3.14   \n",
       "5                     3.47                    0.63                      2.80   \n",
       "6                     5.91                    0.20                      5.46   \n",
       "7                     6.39                    0.32                      5.99   \n",
       "8                     7.68                    0.37                      7.13   \n",
       "9                     8.08                    0.33                      7.54   \n",
       "10                    6.13                    0.41                      5.47   \n",
       "11                    6.55                    0.37                      5.78   \n",
       "\n",
       "    Diversity do(c=1) (99%CI)        variant   black_box  \n",
       "0                        5.26  trainable_cbm      cub_nn  \n",
       "1                        4.67  trainable_cbm      cub_nn  \n",
       "2                        8.07  exogenous_cbm  fraud_lgbm  \n",
       "3                        8.51  exogenous_cbm  fraud_lgbm  \n",
       "4                        5.05  exogenous_cbm      cub_nn  \n",
       "5                        4.47  exogenous_cbm      cub_nn  \n",
       "6                        6.56  trainable_cbm    fraud_nn  \n",
       "7                        6.94  trainable_cbm    fraud_nn  \n",
       "8                        8.08  trainable_cbm  fraud_lgbm  \n",
       "9                        8.65  trainable_cbm  fraud_lgbm  \n",
       "10                       6.88  exogenous_cbm    fraud_nn  \n",
       "11                       7.15  exogenous_cbm    fraud_nn  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results for cub_nn ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 93.1 $\\pm$ 0.52 & 75.48 $\\pm$ 0.53 & 93.9 $\\pm$ 0.56 & 75.52 $\\pm$ 0.59 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 92.89 $\\pm$ 0.7 & 75.69 $\\pm$ 0.6 & 93.78 $\\pm$ 0.68 & 75.52 $\\pm$ 0.47 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 96.87 $\\pm$ 0.18 & 82.62 $\\pm$ 0.13 & 96.19 $\\pm$ 0.29 & 82.57 $\\pm$ 0.12 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 96.92 $\\pm$ 0.18 & 82.62 $\\pm$ 0.17 & 96.45 $\\pm$ 0.23 & 82.57 $\\pm$ 0.17 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 93.75 $\\pm$ 0.24 & 82.49 $\\pm$ 0.12 & 92.37 $\\pm$ 0.84 & 82.41 $\\pm$ 0.12 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 93.61 $\\pm$ 0.26 & 82.55 $\\pm$ 0.21 & 92.23 $\\pm$ 1.11 & 82.5 $\\pm$ 0.21 \\\\\n",
      "\n",
      "\n",
      "\n",
      "==================== Results for cub_nn ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 4.26 $\\pm$ 0.67 & 4.26 $\\pm$ 0.67 & 3.74 $\\pm$ 0.63 & 3.74 $\\pm$ 0.63 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 3.95 $\\pm$ 0.71 & 3.95 $\\pm$ 0.71 & 3.47 $\\pm$ 0.63 & 3.47 $\\pm$ 0.63 \\\\\n",
      "==================== Results for fraud_nn ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 5.91 $\\pm$ 0.2 & 5.91 $\\pm$ 0.2 & 6.39 $\\pm$ 0.32 & 6.39 $\\pm$ 0.32 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 6.13 $\\pm$ 0.41 & 6.13 $\\pm$ 0.41 & 6.55 $\\pm$ 0.37 & 6.55 $\\pm$ 0.37 \\\\\n",
      "==================== Results for fraud_lgbm ===========================\n",
      "\\multicolumn{2}{l|}{Joint CBM ($\\lambda$ = 1)} & 7.68 $\\pm$ 0.37 & 7.68 $\\pm$ 0.37 & 8.08 $\\pm$ 0.33 & 8.08 $\\pm$ 0.33 \\\\\n",
      "\\multicolumn{2}{l|}{Joint CBM w/ Ind. ($\\lambda$ = 1)} & 7.7 $\\pm$ 0.25 & 7.7 $\\pm$ 0.25 & 8.0 $\\pm$ 0.35 & 8.0 $\\pm$ 0.35 \\\\\n"
     ]
    }
   ],
   "source": [
    "variant_dict = {\n",
    "    \"trainable_cbm\": \"Joint CBM\",\n",
    "    \"exogenous_cbm\": \"Joint CBM w/ Ind.\",\n",
    "}\n",
    "\n",
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"trainable_cbm\", \"exogenous_cbm\"]:\n",
    "        group = results_df[\n",
    "            (results_df[\"black_box\"] == bb) & (results_df[\"variant\"] == variant)\n",
    "        ]\n",
    "\n",
    "        validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "        test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "        string = (f\"\\\\multicolumn{{2}}{{l|}}{{{variant_dict[variant]} ($\\lambda$ = 1)}} \"\n",
    "            f\"& {validation['Distillation Mean']} $\\\\pm$ {validation['Distillation Std.']} \"\n",
    "            f\"& {validation['Explainability Mean']} $\\\\pm$ {validation['Explainability Std.']} \"\n",
    "            f\"& {test['Distillation Mean']} $\\\\pm$ {test['Distillation Std.']} \"\n",
    "            f\"& {test['Explainability Mean']} $\\\\pm$ {test['Explainability Std.']} \\\\\\\\\"\n",
    "        )\n",
    "        print(string)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for bb in [\"cub_nn\", \"fraud_nn\", \"fraud_lgbm\"]:\n",
    "    print(f\"==================== Results for {bb} ===========================\")\n",
    "    for variant in [\"trainable_cbm\", \"exogenous_cbm\"]:\n",
    "        group = results_df[\n",
    "            (results_df[\"black_box\"] == bb) & (results_df[\"variant\"] == variant)\n",
    "        ]\n",
    "\n",
    "        validation = group[group[\"Set\"] == \"validation\"].iloc[0]\n",
    "        test = group[group[\"Set\"] == \"test\"].iloc[0]\n",
    "        string = (f\"\\\\multicolumn{{2}}{{l|}}{{{variant_dict[variant]} ($\\lambda$ = 1)}} \"\n",
    "            f\"& {validation['Diversity do(c=0) Mean']} $\\\\pm$ {validation['Diversity do(c=0) Std.']} \"\n",
    "            f\"& {validation['Diversity do(c=1) Mean']} $\\\\pm$ {validation['Diversity do(c=1) Std.']} \"\n",
    "            f\"& {test['Diversity do(c=0) Mean']} $\\\\pm$ {test['Diversity do(c=0) Std.']} \"\n",
    "            f\"& {test['Diversity do(c=1) Mean']} $\\\\pm$ {test['Diversity do(c=1) Std.']} \\\\\\\\\"\n",
    "        )\n",
    "        print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cub_nn'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set                                    validation\n",
       "Method                       trainable_cbm_cub_nn\n",
       "Distillation Mean                            93.1\n",
       "Distillation Std.                            0.52\n",
       "Distillation (1%CI)                         91.56\n",
       "Distillation (99%CI)                        93.67\n",
       "Explainability Mean                         75.48\n",
       "Explainability Std.                          0.53\n",
       "Explainability (1%CI)                       74.79\n",
       "Explainability (99%CI)                      76.12\n",
       "Diversity do(c=0) Mean                       5.98\n",
       "Diversity do(c=0) Std.                       2.63\n",
       "Diversity do(c=0) (1%CI)                     2.32\n",
       "Diversity do(c=0) (99%CI)                   13.42\n",
       "Diversity do(c=1) Mean                        5.7\n",
       "Diversity do(c=1) Std.                       1.87\n",
       "Diversity do(c=1) (1%CI)                     2.32\n",
       "Diversity do(c=1) (99%CI)                    9.94\n",
       "variant                             trainable_cbm\n",
       "black_box                                  cub_nn\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x7faa003d7b50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\n",
    "                (results_df[\"black_box\"] == bb) & (results_df[\"variant\"] == variant)\n",
    "            ].iterrows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}